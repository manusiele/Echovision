# ECOVISION

## A Mobile Application for the Visually and Hearing Impaired

### Project Overview

ECOVISION is a comprehensive mobile application designed to enhance accessibility for individuals who are visually or hearing impaired. Built using Kotlin for Android devices, this application integrates multiple assistive features into a single, user-friendly platform, eliminating the need for multiple specialized applications.

### Features

#### For Visually Impaired Users:
- **Document Scanning & Text-to-Speech**: Scan physical documents and have the text read aloud
- **Object Recognition**: Identify objects in the environment through the device's camera
- **Voice Command Navigation**: Control the application and perform tasks using voice commands

#### For Hearing Impaired Users:
- **Vibration Alerts**: Receive tactile notifications when loud sounds (e.g., vehicle horns, sirens) are detected
- **Text-to-Speech Communication**: Convert written text into speech for verbal communication

#### Shared Features:
- **User Profiles**: Customize settings based on specific needs and preferences
- **Real-time Notifications**: Stay informed about important events and communications
- **Multilingual Support**: Access features in multiple languages
- **User Feedback Mechanism**: Report issues and suggest improvements

### Technical Specifications

#### Hardware Requirements:
- Android smartphone or tablet (Android 5.0 Lollipop or later)
- Minimum 2GB RAM
- 8MP or higher rear camera
- Microphone and vibration motor
- Internet access for certain features

#### Development Tools:
- Kotlin programming language
- Android Studio IDE
- Firebase for database management and authentication
- Google Cloud Vision API for object recognition
- Google Text-to-Speech and Speech-to-Text APIs

### Project Significance

ECOVISION addresses a critical gap in assistive technology by providing an integrated solution for both visually and hearing impaired users. Unlike existing applications that often target only one type of impairment, ECOVISION offers a unified platform with features tailored to both populations. This integration enhances independence, improves social interaction, and provides better navigation capabilities for users with sensory impairments.

### Project Contributions

1. **Enhanced Independence**: Empowers individuals to perform daily tasks without external assistance
2. **Improved Social Interaction**: Facilitates seamless communication between users with different abilities
3. **Better Navigation**: Helps users move safely in various environments
4. **Multi-Functionality**: Combines various assistive tools into a single application
5. **Increased Accessibility**: Features an intuitive and adaptable user interface
6. **Personalized Experience**: Adapts to individual user preferences and needs
7. **Security & Privacy**: Implements strong data protection measures

### Future Directions

- Expansion to iOS platform
- Enhanced AI integration for improved object recognition and speech processing
- Additional language support
- Advanced environmental sound recognition
- Offline functionality for areas with limited connectivity


### Acknowledgements

We extend our gratitude to:
- Our supervisor, Madam Teresa, for her guidance and insights
- The administration for providing a supportive academic environment
- All participants who provided feedback during the development process
